{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj5vQsAXRHmP"
      },
      "source": [
        "# AlexNet à partir de zéro\n",
        "## Introduction\n",
        "AlexNet est un réseau neuronal convolutif profond, qui a été initialement développé par Alex Krizhevsky et ses collègues en 2012. Il a été conçu pour classer les images pour le concours ImageNet LSVRC-2010 où il a obtenu des résultats de pointe.\n",
        "Ici, on va résumer les principaux points à retenir sur le réseau AlexNet. Tout d’abord, il fonctionnait avec des images à 3 canaux de taille (224x224x3). Il utilisait le regroupement maximal ainsi que les activations ReLU lors du sous-échantillonnage. Les noyaux utilisés pour les convolutions étaient soit 11x11, 5x5 ou 3x3 tandis que les noyaux utilisés pour le regroupement maximal avaient une taille de 3x3. Il a classé les images en 1000 classes. Il utilisait également plusieurs GPU.\n",
        "## Chargement des données\n",
        "### Jeu de données\n",
        "Commençons par charger puis prétraiter les données. Pour nos besoins, nous utiliserons le CIFAR10 (ensemble de données). L’ensemble de données se compose de 60000 images couleur 32x32 dans 10 classes, avec 6000 images par classe. Il y a 50000 images d’entraînement et 10000 images de test.\n",
        "\n",
        "Voici les classes de l’ensemble de données, ainsi que 10 exemples d’images aléatoires de chacune :\n",
        "\n",
        "<img src=\"https://github.com/IbnISSA/AlexNet/blob/main/classes.png?raw=1\" alt=\"CIFAR-10\" width=\"500px\">\n",
        "\n",
        "Les classes s’excluent mutuellement. Il n’y a pas de chevauchement entre les automobiles et les camions. « Automobile » comprend les berlines, les SUV et les choses de ce genre. Le terme « Truck » ne comprend que les gros camions. Ni l’un ni l’autre n’inclut les camionnettes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3-m0n_PRHmX"
      },
      "source": [
        "## Importation des bibliothèques\n",
        "Commençons par importer les bibliothèques requises et définir une variable `device`, afin que le notebook sache utiliser un GPU pour entraîner le modèle s’il est disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjrrgkTFRHmY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# Configuration de l'appareil\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab1v9FUuRHmd"
      },
      "source": [
        "## **Chargement du jeu de données**\n",
        "En utilisant `torchvision` (une bibliothèque d’assistance pour les tâches de vision par ordinateur), nous chargerons notre ensemble de données. Cette méthode a des fonctions d’assistance qui rendent le prétraitement assez facile et direct. Définissons les fonctions `get_train_valid_loader` et `get_test_loader`, puis appelons-les pour charger et traiter notre donnée CIFAR-10 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_IBZJQ1RHmg",
        "outputId": "290064d1-2e39-4b20-863b-ad6789f122bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28795469.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def get_train_valid_loader(data_dir,\n",
        "                           batch_size,\n",
        "                           augment,\n",
        "                           random_seed,\n",
        "                           valid_size=0.1,\n",
        "                           shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=train_transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=valid_transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "def get_test_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    )\n",
        "\n",
        "    # define transform\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((227,227)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=False,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# CIFAR10 dataset\n",
        "train_loader, valid_loader = get_train_valid_loader(data_dir = './data', batch_size = 64, augment = False, random_seed = 1)\n",
        "\n",
        "test_loader = get_test_loader(data_dir = './data',\n",
        "                              batch_size = 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZc0m7NvRHmk"
      },
      "source": [
        "Décomposons le code en morceau :\n",
        "- Nous définissons deux fonctions `get_train_valid_loader` et `get_test_loader` pour charger respectivement les ensembles de formation/validation et de test.\n",
        "- Nous commençons par définir la variable `normalize` avec la moyenne et les écarts-types de chacun des canaux (rouge, vert et bleu) dans l’ensemble de données. Ceux-ci peuvent être calculés manuellement, mais sont également disponibles en ligne puisque CIFAR-10 est très populaire.\n",
        "- Pour notre jeu de données d’entraînement, nous ajoutons l’option d’augmenter également le jeu de données pour un entraînement plus robuste et augmenter le nombre d’images. Remarque : l’augmentation n’est appliquée qu’au sous-ensemble d’apprentissage et non aux sous-ensembles de validation et de test, car ils ne sont utilisés qu’à des fins d’évaluation.\n",
        "- Nous divisons le jeu de données d’entraînement en ensembles d’entraînement et de validation (ratio 90:10) et le sous-ensemble aléatoirement à partir de l’ensemble d’entraînement.\n",
        "- Nous spécifions la taille du lot et mélangeons le jeu de données lors du chargement, de sorte que chaque lot présente une certaine variation dans les types d’étiquettes qu’il possède. Cela augmentera l’efficacité de notre modèle éventuel.\n",
        "- Enfin, nous utilisons des chargeurs de données. Cela peut ne pas affecter les performances dans le cas d’un petit jeu de données comme CIFAR10, mais cela peut vraiment entraver les performances dans le cas de grands jeux de données et est généralement considéré comme une bonne pratique. Les chargeurs de données nous permettent d’itérer sur les données par lots, et les données sont chargées pendant l’itération et non toutes en même temps dans votre RAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chUIauqXRHml"
      },
      "source": [
        "## AlexNet à partir de zéro\n",
        "Commençons par le code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TOz-VYn7RHmm"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mi7zSOFRHmn"
      },
      "source": [
        "Voyons comment fonctionne le code ci-dessus :\n",
        "\n",
        "- La première étape pour définir un réseau neuronal (qu’il s’agisse d’un CNN ou non) dans PyTorch est de définir une classe qui hérite `nn.Module` car elle contient de nombreuses méthodes que nous devrons utiliser.\n",
        "- Il y a deux étapes principales après cela. La première consiste à initialiser les couches que nous allons utiliser dans notre CNN à l’intérieur de `__init__`, et l’autre consiste à définir l’ordre dans lequel ces couches traiteront l’image. Ceci est défini à l’intérieur de la fonction `forward`.\n",
        "- Pour l’architecture elle-même, nous définissons d’abord les couches convolutives à l’aide de la fonction `nn.Conv2D` avec la taille de noyau appropriée et les canaux d’entrée/sortie. Nous appliquons également la fonction de mise en commun maximale `nn.MaxPool2D`. La bonne chose à propos de PyTorch est que nous pouvons combiner la couche convolutive, la fonction d’activation et le pool maximum en une seule couche (ils seront appliqués séparément, mais cela aide à l’organisation) en utilisant la fonction `nn.Sequential`\n",
        "- Ensuite, nous définissons les couches entièrement connectées en utilisant linear (`nn.Linear`) et dropout (`nn.Dropout`) ainsi que la fonction d’activation ReLu (`nn.ReLU`) et les combinons avec la fonction `nn.Sequential`.\n",
        "- Enfin, notre dernière couche produit 10 neurones qui sont nos prédictions finales pour les 10 classes d’objets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll3nTe5JRHmo"
      },
      "source": [
        "## **Définition des hyperparamètres**\n",
        "Avant l’entraînement, nous devons définir certaines hyperparamètres, tels que la fonction de perte et l’optimiseur à utiliser, ainsi que la taille du lot, le taux d’apprentissage et le nombre d’époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zt4Zo3MmRHmp"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 0.005\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdFxE_QXRHmp"
      },
      "source": [
        "Nous commençons par définir des hyperparamètres simples (époques, taille de lot et taux d'apprentissage) et initialisons notre modèle en utilisant le nombre de classes comme argument, qui dans ce cas est de 10, ainsi que le transfert du modèle vers le périphérique approprié (CPU ou GPU). Ensuite, nous définissons notre fonction de coût comme perte d'entropie croisée et notre optimiseur comme Adam. Il existe de nombreux choix pour ceux-ci, mais ceux-ci ont tendance à donner de bons résultats avec le modèle et les données fournies. Enfin, nous définissons `total_step` pour mieux suivre les étapes lors de l'entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOSCKP-CRHmp"
      },
      "source": [
        "## Entrainement\n",
        "Nous sommes prêts à entraîner notre modèle à ce stade :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8-RitGpRHmq",
        "outputId": "6a9ea089-712f-4de2-d6a2-e9b0e62c5a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [704/704], Loss: 1.2305\n",
            "Accuracy of the network on the 5000 validation images: 60.12 %\n",
            "Epoch [2/20], Step [704/704], Loss: 1.0509\n",
            "Accuracy of the network on the 5000 validation images: 67.98 %\n",
            "Epoch [3/20], Step [704/704], Loss: 1.1021\n",
            "Accuracy of the network on the 5000 validation images: 72.36 %\n",
            "Epoch [4/20], Step [704/704], Loss: 0.7622\n",
            "Accuracy of the network on the 5000 validation images: 73.2 %\n",
            "Epoch [5/20], Step [704/704], Loss: 1.5573\n",
            "Accuracy of the network on the 5000 validation images: 76.1 %\n",
            "Epoch [6/20], Step [704/704], Loss: 0.5973\n",
            "Accuracy of the network on the 5000 validation images: 76.28 %\n",
            "Epoch [7/20], Step [704/704], Loss: 1.0499\n",
            "Accuracy of the network on the 5000 validation images: 78.26 %\n",
            "Epoch [8/20], Step [704/704], Loss: 0.2122\n",
            "Accuracy of the network on the 5000 validation images: 79.76 %\n",
            "Epoch [9/20], Step [704/704], Loss: 0.2618\n",
            "Accuracy of the network on the 5000 validation images: 79.4 %\n",
            "Epoch [10/20], Step [704/704], Loss: 0.4803\n",
            "Accuracy of the network on the 5000 validation images: 80.52 %\n",
            "Epoch [11/20], Step [704/704], Loss: 0.5358\n",
            "Accuracy of the network on the 5000 validation images: 78.54 %\n",
            "Epoch [12/20], Step [704/704], Loss: 0.0984\n",
            "Accuracy of the network on the 5000 validation images: 80.72 %\n",
            "Epoch [13/20], Step [704/704], Loss: 0.2972\n",
            "Accuracy of the network on the 5000 validation images: 81.56 %\n",
            "Epoch [14/20], Step [704/704], Loss: 0.0867\n",
            "Accuracy of the network on the 5000 validation images: 81.44 %\n",
            "Epoch [15/20], Step [704/704], Loss: 0.6545\n",
            "Accuracy of the network on the 5000 validation images: 81.38 %\n",
            "Epoch [16/20], Step [704/704], Loss: 0.1672\n",
            "Accuracy of the network on the 5000 validation images: 80.48 %\n",
            "Epoch [17/20], Step [704/704], Loss: 0.6057\n",
            "Accuracy of the network on the 5000 validation images: 83.66 %\n",
            "Epoch [18/20], Step [704/704], Loss: 0.2218\n",
            "Accuracy of the network on the 5000 validation images: 82.3 %\n",
            "Epoch [19/20], Step [704/704], Loss: 0.9763\n",
            "Accuracy of the network on the 5000 validation images: 81.42 %\n",
            "Epoch [20/20], Step [704/704], Loss: 0.4654\n",
            "Accuracy of the network on the 5000 validation images: 82.62 %\n"
          ]
        }
      ],
      "source": [
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3qfcD3aRHmq"
      },
      "source": [
        "Voyons ce que fait le code :\n",
        "\n",
        "- Nous commençons par itérer sur le nombre d’époques, puis sur les lots dans nos données d’entraînement\n",
        "- Nous convertissons les images et les étiquettes en fonction de l’appareil que nous utilisons, c’est-à-dire GPU ou CPU\n",
        "- Dans le forward pass, nous faisons des prédictions à l’aide de notre modèle et calculons la perte en fonction de ces prédictions et de nos étiquettes réelles\n",
        "- Ensuite, nous effectuons la passe arrière où nous mettons à jour nos poids pour améliorer notre modèle\n",
        "- Nous mettons ensuite les dégradés à zéro avant chaque mise à jour à l’aide de la fonction `optimizer.zero_grad()`\n",
        "- Ensuite, nous calculons les nouveaux gradients à l’aide de la fonction `loss.backward()`\n",
        "- Et enfin, nous mettons à jour les poids avec la fonction `optimizer.step()`\n",
        "- De plus, à la fin de chaque époque, nous utilisons également notre jeu de validation pour calculer la précision du modèle. Dans ce cas, nous n’avons pas besoin de gradients, nous utilisons `with torch.no_grad()` donc pour une évaluation plus rapide\n",
        "\n",
        "\n",
        "Nous pouvons voir la sortie(ci-dessus) comme une suite de Perte d’entraînement et précision de la validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3wG9r4xRHmr"
      },
      "source": [
        "Comme nous pouvons le constater, la perte diminue à chaque époque, ce qui montre que notre modèle est effectivement en train d’apprendre. Notez que cette perte se trouve sur l’ensemble d’apprentissage, et si la perte est beaucoup trop faible, cela peut indiquer un surapprentissage. C’est pourquoi nous utilisons également le kit de validation. La précision semble augmenter sur l’ensemble de validation, ce qui indique qu’il y a peu de chances de surapprentissage. Testons maintenant notre modèle pour voir comment il fonctionne."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43GUwSkqRHmr"
      },
      "source": [
        "## Test\n",
        "Maintenant, voyons comment notre modèle se comporte sur des données invisibles :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReJl50jJRHmr",
        "outputId": "d09e16c6-6cd4-419b-922d-966ec051eaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 81.95 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLOnuj8ZRHmr"
      },
      "source": [
        "Notez que le code est exactement le même que pour nos besoins de validation.\n",
        "\n",
        "En utilisant le modèle et en nous entraînant pour seulement nos 20 époques, nous semblons obtenir une précision d’environ 78,8 % sur l’ensemble de validation, ce qui semble suffisant.<br><br>\n",
        "(Voir La Précision des tests ci-dessus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d17Tu1BPRHms"
      },
      "source": [
        "## Conclusion\n",
        "Concluons maintenant ce que nous avons fait :\n",
        "\n",
        "- Nous avons commencé par comprendre l’architecture et les différents types de couches du modèle AlexNet\n",
        "- Ensuite, nous avons chargé et prétraité le jeu de données CIFAR10 à l’aide de `torchvision`\n",
        "- Ensuite, nous avons utilisé `PyTorch` pour créer notre modèle AlexNet à partir de zéro.\n",
        "- Enfin, nous avons entraîné et testé notre modèle sur le jeu de données CIFAR10, et le modèle semblait bien fonctionner sur le jeu de données de test avec un entraînement minimal (20 époques)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}